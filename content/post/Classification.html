---
title: Classification
date: 2018-03-03 21:59:59
tags: [classification, R, ISLR]
categories: 读书笔记
mathjax: true
toc: true
---


<div id="TOC">
true
</div>

<p>第四章讲的是分类，又涨知识了…… 源文件地址：<a href="https://github.com/ditannan/learn_ML/blob/ISLR/ISLR/Classification.ipynb">Classification</a>，源文件看着更顺眼，只能说还不太能完全展示原效果，还要继续学习……</p>
<div id="linear-discriminant-analysis-lda" class="section level1">
<h1>线性判别分析（linear discriminant analysis, LDA）</h1>
<ul>
<li>在类别区分度高时，logistic回归模型参数不够稳定，这点在线性判别不存在</li>
<li>如果样本量n比较小，而且在每一类响应分类中预测变量X近似服从正态分布，那么线性判别比logistic回归更稳定</li>
<li>响应变量分类多于两类时，线性判别分析应用更普遍</li>
</ul>
<!-- more-->
<div class="section level2">
<h2>运用贝叶斯定理进行分类</h2>
<p><span class="math inline">\(K\geq2\)</span>，设<span class="math inline">\(\pi_k\)</span>为一个随机选择的观测来自第k类的<strong>先验</strong>概率，<span class="math inline">\(f_k(X)\equiv Pr(X=x|Y=k)\)</span>表示第k类观测的X的<strong>密度函数</strong>。则<strong>贝叶斯定理</strong>表述为： <span class="math display">\[p_k(X)=Pr(Y=k|X=x)=\frac{\pi_kf_k(x)}{\sum_{i=1}^K\pi_if_i(x)}\tag{4-1}\]</span> <span class="math inline">\(p_k(X)\)</span>为<span class="math inline">\(X=x\)</span>的观测属于第k类的后验概率。</p>
</div>
<div id="p1" class="section level2">
<h2>p=1的线性判别分析</h2>
<p>分类器名称中的“线性”一词是由于判别函数中<span class="math inline">\(\delta_k(x)\)</span>是x的线性函数。LDA分类器的结果是建立在每一类中的观测都来自于一个均值不同、方差相同（均为<span class="math inline">\(\sigma^2\)</span>）的正态分布假设上的。将这些参数估计带入（4-1）贝叶斯分类器中得到LDA分类器。</p>
</div>
<div id="quadratic-discriminant-analysis-qda" class="section level2">
<h2>二次判别分析（quadratic discriminant analysis, QDA）</h2>
<p>QDA分类器也是假设每一类观测服从一个高斯分布，把参数估计带入贝叶斯分类器中，与LDA不同的是，QDA假设每一类观测都有自己的协方差矩阵。<span class="math inline">\(\delta_k(x)\)</span>是x的二次函数。</p>
<p>LDA没有QDA分类器光滑，于是拥有更低的方差，该模型有改善预测效果的潜力。一般而言，如果训练观测数据相对较少，LDA比QDA更好，降低模型的方差很有必要。如果训练集很大，QDA更好，因为K类的协方差矩阵形同的假设很难成立。</p>
</div>
<div class="section level2">
<h2>分类方法比较</h2>
<ul>
<li>LDA假设观测服从每一类协方差矩阵都相同的高斯分布，当其成立时，LDA比logistic能提供更好的结果，反之亦然。</li>
<li>KNN是非参数方法，当决策边界高度非线性时，用该方法优于LDA和logistic，但无法得到系数估计。</li>
<li>QDA是非参数KNN和线性LDA、logistic之间的一个折中方法。</li>
</ul>
</div>
</div>
<div id="r" class="section level1">
<h1>R操作</h1>
<pre class="r"><code># loading packages
library(&quot;ISLR&quot;)
library(&quot;magrittr&quot;)
library(&quot;dplyr&quot;)
library(&quot;ggplot2&quot;)</code></pre>
<div class="section level2">
<h2>股票市场数据</h2>
<p>Direction为股票涨跌</p>
<pre class="r"><code>glimpse(Smarket)</code></pre>
<pre><code>Observations: 1,250
Variables: 9
$ Year      &lt;dbl&gt; 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 200...
$ Lag1      &lt;dbl&gt; 0.381, 0.959, 1.032, -0.623, 0.614, 0.213, 1.392, -0.403,...
$ Lag2      &lt;dbl&gt; -0.192, 0.381, 0.959, 1.032, -0.623, 0.614, 0.213, 1.392,...
$ Lag3      &lt;dbl&gt; -2.624, -0.192, 0.381, 0.959, 1.032, -0.623, 0.614, 0.213...
$ Lag4      &lt;dbl&gt; -1.055, -2.624, -0.192, 0.381, 0.959, 1.032, -0.623, 0.61...
$ Lag5      &lt;dbl&gt; 5.010, -1.055, -2.624, -0.192, 0.381, 0.959, 1.032, -0.62...
$ Volume    &lt;dbl&gt; 1.1913, 1.2965, 1.4112, 1.2760, 1.2057, 1.3491, 1.4450, 1...
$ Today     &lt;dbl&gt; 0.959, 1.032, -0.623, 0.614, 0.213, 1.392, -0.403, 0.027,...
$ Direction &lt;fctr&gt; Up, Up, Down, Up, Up, Up, Down, Up, Up, Up, Down, Down, ...</code></pre>
<div id="logistic" class="section level3">
<h3>拟合logistic回归模型</h3>
<pre class="r"><code>glm.logis &lt;- Smarket %$% 
  glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, family = binomial)
summary(glm.logis)</code></pre>
<pre><code>Call:
glm(formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + 
    Volume, family = binomial)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.446  -1.203   1.065   1.145   1.326  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept) -0.126000   0.240736  -0.523    0.601
Lag1        -0.073074   0.050167  -1.457    0.145
Lag2        -0.042301   0.050086  -0.845    0.398
Lag3         0.011085   0.049939   0.222    0.824
Lag4         0.009359   0.049974   0.187    0.851
Lag5         0.010313   0.049511   0.208    0.835
Volume       0.135441   0.158360   0.855    0.392

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1731.2  on 1249  degrees of freedom
Residual deviance: 1727.6  on 1243  degrees of freedom
AIC: 1741.6

Number of Fisher Scoring iterations: 3</code></pre>
<div class="section level4">
<h4>模型拟合系数</h4>
<pre class="r"><code># 拟合模型系数
summary(glm.logis)$coef</code></pre>
<table>
<thead>
<tr>
<th>
</th>
<th scope="col">
Estimate
</th>
<th scope="col">
Std. Error
</th>
<th scope="col">
z value
</th>
<th scope="col">
Pr(&gt;|z|)
</th>
</tr>
</thead>
<tbody>
<pre><code>&lt;tr&gt;&lt;th scope=row&gt;(Intercept)&lt;/th&gt;&lt;td&gt;-0.126000257&lt;/td&gt;&lt;td&gt;0.24073574  &lt;/td&gt;&lt;td&gt;-0.5233966  &lt;/td&gt;&lt;td&gt;0.6006983   &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th scope=row&gt;Lag1&lt;/th&gt;&lt;td&gt;-0.073073746&lt;/td&gt;&lt;td&gt;0.05016739  &lt;/td&gt;&lt;td&gt;-1.4565986  &lt;/td&gt;&lt;td&gt;0.1452272   &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th scope=row&gt;Lag2&lt;/th&gt;&lt;td&gt;-0.042301344&lt;/td&gt;&lt;td&gt;0.05008605  &lt;/td&gt;&lt;td&gt;-0.8445733  &lt;/td&gt;&lt;td&gt;0.3983491   &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th scope=row&gt;Lag3&lt;/th&gt;&lt;td&gt; 0.011085108&lt;/td&gt;&lt;td&gt;0.04993854  &lt;/td&gt;&lt;td&gt; 0.2219750  &lt;/td&gt;&lt;td&gt;0.8243333   &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th scope=row&gt;Lag4&lt;/th&gt;&lt;td&gt; 0.009358938&lt;/td&gt;&lt;td&gt;0.04997413  &lt;/td&gt;&lt;td&gt; 0.1872757  &lt;/td&gt;&lt;td&gt;0.8514445   &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th scope=row&gt;Lag5&lt;/th&gt;&lt;td&gt; 0.010313068&lt;/td&gt;&lt;td&gt;0.04951146  &lt;/td&gt;&lt;td&gt; 0.2082966  &lt;/td&gt;&lt;td&gt;0.8349974   &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th scope=row&gt;Volume&lt;/th&gt;&lt;td&gt; 0.135440659&lt;/td&gt;&lt;td&gt;0.15835970  &lt;/td&gt;&lt;td&gt; 0.8552723  &lt;/td&gt;&lt;td&gt;0.3924004   &lt;/td&gt;&lt;/tr&gt;</code></pre>
</tbody>
</table>
<div class="section level5">
<h5>预测概率</h5>
<pre class="r"><code>glm.probs &lt;- predict(glm.logis, type = &#39;response&#39;) ## 预测训练数据集</code></pre>
</div>
<div class="section level5">
<h5>将预测概率转化为分类</h5>
<pre class="r"><code>glm.pred &lt;- rep(&#39;Down&#39;, nrow(Smarket))
glm.pred[glm.probs &gt; .5] &lt;- &#39;Up&#39;</code></pre>
</div>
<div class="section level5">
<h5>预测情况</h5>
<pre class="r"><code># 预测和原始比较
table(glm.pred, Smarket$Direction)
# 训练集预测率
mean(glm.pred == Smarket$Direction)</code></pre>
<pre><code>glm.pred Down  Up
    Down  145 141
    Up    457 507</code></pre>
<p>0.5216</p>
<p>在训练集的正确率尚如此，在测试集还会差一些</p>
</div>
<div id="2005" class="section level5">
<h5>将数据分为训练集和测试集，2005年之前为训练集</h5>
<pre class="r"><code># 选择训练集和测试集
train &lt;- Smarket$Year &lt; 2005
Smarket.2005 &lt;- Smarket[!train, ]
Smarket.train &lt;- Smarket[train, ]
# 使用测试集拟合模型
glm.logis.train &lt;- Smarket.train %$%
  glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, family = binomial)</code></pre>
</div>
<div id="-1" class="section level5">
<h5>预测情况</h5>
<pre class="r"><code># 预测测试集
glm.probs.test &lt;- predict(glm.logis.train, Smarket.2005, type = &#39;response&#39;)
glm.pred.test &lt;- rep(&#39;Down&#39;, nrow(Smarket.2005))
glm.pred.test[glm.probs.test &gt; .5] &lt;- &#39;Up&#39;
table(glm.pred.test, Smarket.2005$Direction)
# 测试集预测率
mean(glm.pred.test == Smarket.2005$Direction)</code></pre>
<pre><code>glm.pred.test Down Up
         Down   77 97
         Up     34 44</code></pre>
<p>0.48015873015873</p>
<div class="section level6">
<h6>看吧，在测试集预测还不如我随便猜呢……</h6>
</div>
</div>
<div id="p" class="section level5">
<h5>选取p较小的两个变量进行预测</h5>
<pre class="r"><code># 选取p值最小的两个变量进行预测
glm.logis.two.train &lt;- Smarket.train %$%
  glm(Direction ~ Lag1 + Lag2, family = binomial)
# 预测测试集
glm.probs.two.test &lt;- predict(glm.logis.two.train, Smarket.2005, type = &#39;response&#39;)
glm.pred.two.test &lt;- rep(&#39;Down&#39;, nrow(Smarket.2005))
glm.pred.two.test[glm.probs.two.test &gt; .5] &lt;- &#39;Up&#39;
# 预测率
mean(glm.pred.two.test == Smarket.2005$Direction)</code></pre>
<p>0.55952380952381</p>
<div class="section level6">
<h6>恩，预测正确率有所提升……</h6>
</div>
</div>
</div>
</div>
<div id="lda" class="section level3">
<h3>LDA模型</h3>
<p>所使用函数为<code>MASS</code>包中的<code>lda</code>。</p>
<pre class="r"><code># 载入函数
lda &lt;- MASS::lda
# 拟合LDA
lda.fit &lt;- Smarket %$% 
  lda(Direction ~ Lag1 + Lag2, subset = train)
lda.fit</code></pre>
<pre><code>Call:
lda(Direction ~ Lag1 + Lag2, subset = train)

Prior probabilities of groups:
    Down       Up 
0.491984 0.508016 

Group means:
            Lag1        Lag2
Down  0.04279022  0.03389409
Up   -0.03954635 -0.03132544

Coefficients of linear discriminants:
            LD1
Lag1 -0.6420190
Lag2 -0.5135293</code></pre>
<pre class="r"><code># 线性判别图像
plot(lda.fit)</code></pre>
<div class="figure">
<img src="\images\output_31_0.png" alt="png" />
<p class="caption">png</p>
</div>
<div id="-2" class="section level6">
<h6>预测情况</h6>
<pre class="r"><code>lda.pred &lt;- predict(lda.fit, Smarket.2005)
str(lda.pred)
# 测试集预测率
table(lda.pred$class, Smarket.2005$Direction)
mean(lda.pred$class == Smarket.2005$Direction)</code></pre>
<pre><code>List of 3
 $ class    : Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 2 2 2 2 2 2 2 2 ...
 $ posterior: num [1:252, 1:2] 0.49 0.479 0.467 0.474 0.493 ...
  ..- attr(*, &quot;dimnames&quot;)=List of 2
  .. ..$ : chr [1:252] &quot;999&quot; &quot;1000&quot; &quot;1001&quot; &quot;1002&quot; ...
  .. ..$ : chr [1:2] &quot;Down&quot; &quot;Up&quot;
 $ x        : num [1:252, 1] 0.0829 0.5911 1.1672 0.8334 -0.0379 ...
  ..- attr(*, &quot;dimnames&quot;)=List of 2
  .. ..$ : chr [1:252] &quot;999&quot; &quot;1000&quot; &quot;1001&quot; &quot;1002&quot; ...
  .. ..$ : chr &quot;LD1&quot;




       Down  Up
  Down   35  35
  Up     76 106</code></pre>
<p>0.55952380952381</p>
</div>
<div id="logistic" class="section level6">
<h6>看吧，和logistic一样的结果……</h6>
</div>
</div>
<div id="qda" class="section level3">
<h3>QDA模型</h3>
<pre class="r"><code># 载入函数
qda &lt;- MASS::qda
qda.fit &lt;- Smarket %$% 
  qda(Direction ~ Lag1 + Lag2, subset = train)
qda.fit</code></pre>
<pre><code>Call:
qda(Direction ~ Lag1 + Lag2, subset = train)

Prior probabilities of groups:
    Down       Up 
0.491984 0.508016 

Group means:
            Lag1        Lag2
Down  0.04279022  0.03389409
Up   -0.03954635 -0.03132544</code></pre>
<div class="section level6">
<h6>测试集预测概率</h6>
<pre class="r"><code>qda.pred &lt;- predict(qda.fit, Smarket.2005)
str(qda.pred)</code></pre>
<pre><code>List of 2
 $ class    : Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 2 2 2 2 2 2 2 2 ...
 $ posterior: num [1:252, 1:2] 0.487 0.476 0.464 0.474 0.49 ...
  ..- attr(*, &quot;dimnames&quot;)=List of 2
  .. ..$ : chr [1:252] &quot;999&quot; &quot;1000&quot; &quot;1001&quot; &quot;1002&quot; ...
  .. ..$ : chr [1:2] &quot;Down&quot; &quot;Up&quot;</code></pre>
</div>
<div id="-3" class="section level6">
<h6>预测情况</h6>
<pre class="r"><code># 预测情况
table(qda.pred$class, Smarket.2005$Direction)
mean(qda.pred$class == Smarket.2005$Direction)</code></pre>
<pre><code>       Down  Up
  Down   30  20
  Up     81 121</code></pre>
<p>0.599206349206349</p>
</div>
<div class="section level6">
<h6>不错不错，比前两个都好……</h6>
</div>
</div>
<div id="knn" class="section level3">
<h3>KNN模型</h3>
<p>使用<code>class</code>包中的<code>knn</code>函数。需要输入四个参数。knn(train, test, cl, k = 1, l = 0, prob = FALSE, use.all = TRUE)</p>
<pre class="r"><code>library(&quot;class&quot;)
train.x &lt;- Smarket %$% cbind(Lag1, Lag2)[train, ]
test.x &lt;- Smarket %$% cbind(Lag1, Lag2)[!train, ]
train.dir &lt;- Smarket$Direction[train]</code></pre>
<pre class="r"><code>set.seed(1)
knn.pred &lt;- knn(train.x, test.x, train.dir, k = 1)</code></pre>
<div id="-4" class="section level6">
<h6>预测情况</h6>
<pre class="r"><code># 预测情况
table(knn.pred, Smarket.2005$Direction)
mean(knn.pred == Smarket.2005$Direction)</code></pre>
<pre><code>knn.pred Down Up
    Down   43 58
    Up     68 83</code></pre>
<p>0.5</p>
<p>在k=1时正确率刚好50%……我们再看看k=3</p>
<pre class="r"><code># k=3模型
knn.pred.3k &lt;- knn(train.x, test.x, train.dir, k = 3)
# 预测情况
table(knn.pred.3k, Smarket.2005$Direction)
mean(knn.pred.3k == Smarket.2005$Direction)</code></pre>
<pre><code>knn.pred.3k Down Up
       Down   48 54
       Up     63 87</code></pre>
<p>0.535714285714286</p>
</div>
<div id="53" class="section level6">
<h6>不错，53%了……</h6>
</div>
</div>
<div id="knn" class="section level3">
<h3>大篷车保险数据KNN</h3>
<pre class="r"><code>dim(Caravan)
table(Caravan$Purchase)</code></pre>
<pre><code>  No  Yes 
5474  348 </code></pre>
<div id="582286348" class="section level6">
<h6>数据有5822条，86个变量，其中买保险的有348个。我们先标化数据：</h6>
<pre class="r"><code># 标化数据
Caravan.std &lt;- scale(Caravan[, -86])
data.class(Caravan.std)</code></pre>
<p>‘matrix’</p>
<pre class="r"><code># 前1000个为测试集
test &lt;- 1 : 1000
train.x &lt;- Caravan.std[-test, ]
test.x &lt;- Caravan.std[test, ]
train.y &lt;- Caravan$Purchase[-test]
test.y &lt;- Caravan$Purchase[test]</code></pre>
<pre class="r"><code>set.seed(1)
knn.pred.car &lt;- knn(train.x, test.x, train.y, k = 1)
# 预测情况
# 准确率
mean(test.y == knn.pred.car)
mean(knn.pred.car == &#39;Yes&#39;)
table(knn.pred.car, test.y) ## 预测了9/77购买</code></pre>
<p>0.882</p>
<p>0.077</p>
<pre><code>            test.y
knn.pred.car  No Yes
         No  873  50
         Yes  68   9</code></pre>
</div>
<div class="section level6">
<h6>看着好像不错的样子，其实不然，因为</h6>
<pre class="r"><code>9 / 77
# 购买占比例
mean(test.y == &#39;Yes&#39;)</code></pre>
<p>0.116883116883117</p>
<p>0.059</p>
</div>
<div id="k3" class="section level6">
<h6>当k=3时</h6>
<pre class="r"><code>## 当k = 3
knn.pred.car &lt;- knn(train.x, test.x, train.y, k = 3)
# 预测情况
# 准确率
mean(test.y == knn.pred.car)
mean(knn.pred.car == &#39;Yes&#39;)
table(knn.pred.car, test.y) ## 预测了5/26购买</code></pre>
<p>0.925</p>
<p>0.026</p>
<pre><code>            test.y
knn.pred.car  No Yes
         No  920  54
         Yes  21   5</code></pre>
<pre class="r"><code>5 / 26</code></pre>
<p>0.192307692307692</p>
</div>
<div id="19" class="section level6">
<h6>预测了19%的购买</h6>
</div>
<div id="k5" class="section level6">
<h6>当k=5时</h6>
<pre class="r"><code>## 当k = 5
knn.pred.car &lt;- knn(train.x, test.x, train.y, k = 5)
# 预测情况
# 准确率
mean(test.y == knn.pred.car)
mean(knn.pred.car == &#39;Yes&#39;)
table(knn.pred.car, test.y) ## 预测了4/15购买</code></pre>
<p>0.934</p>
<p>0.015</p>
<pre><code>            test.y
knn.pred.car  No Yes
         No  930  55
         Yes  11   4</code></pre>
<pre class="r"><code>4 / 15</code></pre>
<p>0.266666666666667</p>
</div>
<div id="26.6" class="section level6">
<h6>预测了26.6%</h6>
</div>
</div>
<div id="logistic" class="section level3">
<h3>大篷车logistic模型</h3>
<pre class="r"><code>glm.fit.car &lt;- glm(Purchase ~ .,data = Caravan, family =binomial, subset = -test)
glm.fit.car.probs &lt;- predict(glm.fit.car, Caravan[test, ], type = &#39;response&#39;)
glm.pred.car &lt;- rep(&#39;No&#39;, 1000)
glm.pred.car[glm.fit.car.probs &gt; .5] &lt;- &#39;Yes&#39;
table(glm.pred.car, test.y)</code></pre>
<pre><code>Warning message:
&quot;glm.fit: fitted probabilities numerically 0 or 1 occurred&quot;


            test.y
glm.pred.car  No Yes
         No  934  59
         Yes   7   0</code></pre>
<div id="7sad0.25" class="section level6">
<h6>预测了7个购买，还都预测错了，sad……我们把概率阈值下调到0.25看看</h6>
<pre class="r"><code># 阈值改为.25
glm.pred.car[glm.fit.car.probs &gt; .25] &lt;- &#39;Yes&#39;
# 预测情况
table(glm.pred.car, test.y) ## 11/33</code></pre>
<pre><code>            test.y
glm.pred.car  No Yes
         No  919  48
         Yes  22  11</code></pre>
<pre class="r"><code>11 / 33</code></pre>
<p>0.333333333333333</p>
</div>
<div class="section level6">
<h6>不错不错……</h6>
<p>好吧，这章还没学透，回头再回来继续学,习题也很多，挑几道改天做吧……要去学点别的东东了……</p>
</div>
</div>
</div>
</div>
